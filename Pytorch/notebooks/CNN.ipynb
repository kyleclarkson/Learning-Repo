{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Using A CNN (and CIFAR-10)\n",
    "---\n",
    "\n",
    "In this notebook we implement a convolutional neural network to classify low quality images (from the CIFAR-10) dataset where each entry belongs to exactly one of 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get training and validation datasets from PyTorch\n",
    "# Pass both to dataloaders for sampling batches. \n",
    "\n",
    "data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\data\\\\'\n",
    "# Define a transform to normalize the 3 channels of each image to 0.5 and 0.5 mean, std dev.\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(data_path, train=True, download=True,  transform=transform)\n",
    "val_set = torchvision.datasets.CIFAR10(data_path, train=False, download=True,  transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper Functions, members ===\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Show image \n",
    "def imshow(img):\n",
    "    # display an image\n",
    "    img = img / 2 + 0.5 # unnormalize image to [0,1]\n",
    "    npimg = img.numpy()\n",
    "    # Display image by reordering channels to match pyplot's expectation\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "# Training loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "    # loop over epochs\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        \n",
    "        # iter over training batch\n",
    "        for imgs, labels in train_loader:\n",
    "            # convert tensors to device\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            y_pred = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "                \n",
    "        # display training loss\n",
    "        if epoch % 10 == 0 or epoch == 1: \n",
    "            loss = loss_train / len(train_loader)\n",
    "            print(f'{datetime.datetime.now()} Epoch: {epoch}, Training loss: {loss:.3f}')\n",
    "            validate(model, train_loader, val_loader)\n",
    "            \n",
    "# Validation loop\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"validate\", val_loader)]:\n",
    "        correct_pred, total = 0, 0\n",
    "        # disable tracking of operations \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                # convert tensors to device\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                y_preds = model(imgs)\n",
    "                _, predicted = torch.max(y_preds, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                # compare agreements between predicted and labels, sum and add to running total. \n",
    "                correct_pred += int((predicted==labels).sum())\n",
    "        print(f'Accuracy: {name} {correct_pred/total:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Define CNN\n",
    "###\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # take 3x32x32 --> 6x32x32 \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, padding=1)\n",
    "        # downsample 6x32x32 --> 6x16x16\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # convolve 6x16x16 --> 8x16x16\n",
    "        self.conv2 = nn.Conv2d(6, 8, kernel_size=3, padding=1)\n",
    "        # convolve 8x16x16 --> 8x8x8\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        # flatten 8x8x8 --> 64x1\n",
    "        self.fc1 = nn.Linear(8*8*8, 64)\n",
    "        # flatten 64x1 --> 32x1\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        # flatten 64x1 --> 32x1\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        # flatten 32x1 --> 10x1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolution, activation function, and pooling to input\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # reshape x to match first linear layer\n",
    "        x = x.view(-1, 8*8*8)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 16:22:03.420076 Epoch: 1, Training loss: 2.309\n",
      "Accuracy: train 0.100\n",
      "Accuracy: validate 0.100\n",
      "2020-10-16 16:24:33.217186 Epoch: 10, Training loss: 2.302\n",
      "Accuracy: train 0.101\n",
      "Accuracy: validate 0.100\n",
      "2020-10-16 16:27:08.486036 Epoch: 20, Training loss: 2.287\n",
      "Accuracy: train 0.166\n",
      "Accuracy: validate 0.168\n",
      "2020-10-16 16:29:44.068601 Epoch: 30, Training loss: 2.136\n",
      "Accuracy: train 0.235\n",
      "Accuracy: validate 0.243\n",
      "2020-10-16 16:32:20.049918 Epoch: 40, Training loss: 1.929\n",
      "Accuracy: train 0.307\n",
      "Accuracy: validate 0.310\n",
      "2020-10-16 16:34:57.293646 Epoch: 50, Training loss: 1.805\n",
      "Accuracy: train 0.352\n",
      "Accuracy: validate 0.358\n",
      "2020-10-16 16:37:37.194800 Epoch: 60, Training loss: 1.671\n",
      "Accuracy: train 0.406\n",
      "Accuracy: validate 0.416\n",
      "2020-10-16 16:40:18.914544 Epoch: 70, Training loss: 1.581\n",
      "Accuracy: train 0.431\n",
      "Accuracy: validate 0.436\n",
      "2020-10-16 16:43:01.575840 Epoch: 80, Training loss: 1.511\n",
      "Accuracy: train 0.459\n",
      "Accuracy: validate 0.457\n",
      "2020-10-16 16:45:37.208600 Epoch: 90, Training loss: 1.448\n",
      "Accuracy: train 0.473\n",
      "Accuracy: validate 0.473\n",
      "2020-10-16 16:48:14.437559 Epoch: 100, Training loss: 1.385\n",
      "Accuracy: train 0.499\n",
      "Accuracy: validate 0.489\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(100, opt, model, loss_fn, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 16:48:54.663112 Epoch: 1, Training loss: 1.378\n",
      "Accuracy: train 0.507\n",
      "Accuracy: validate 0.497\n",
      "2020-10-16 16:51:29.790516 Epoch: 10, Training loss: 1.329\n",
      "Accuracy: train 0.511\n",
      "Accuracy: validate 0.505\n",
      "2020-10-16 16:54:09.050409 Epoch: 20, Training loss: 1.283\n",
      "Accuracy: train 0.543\n",
      "Accuracy: validate 0.529\n",
      "2020-10-16 16:56:47.296551 Epoch: 30, Training loss: 1.244\n",
      "Accuracy: train 0.548\n",
      "Accuracy: validate 0.538\n",
      "2020-10-16 16:59:25.730105 Epoch: 40, Training loss: 1.210\n",
      "Accuracy: train 0.564\n",
      "Accuracy: validate 0.552\n",
      "2020-10-16 17:02:04.282921 Epoch: 50, Training loss: 1.179\n",
      "Accuracy: train 0.576\n",
      "Accuracy: validate 0.553\n",
      "2020-10-16 17:04:42.777710 Epoch: 60, Training loss: 1.150\n",
      "Accuracy: train 0.582\n",
      "Accuracy: validate 0.562\n",
      "2020-10-16 17:07:21.694377 Epoch: 70, Training loss: 1.121\n",
      "Accuracy: train 0.603\n",
      "Accuracy: validate 0.571\n",
      "2020-10-16 17:10:00.005311 Epoch: 80, Training loss: 1.097\n",
      "Accuracy: train 0.611\n",
      "Accuracy: validate 0.581\n",
      "2020-10-16 17:12:37.872334 Epoch: 90, Training loss: 1.074\n",
      "Accuracy: train 0.623\n",
      "Accuracy: validate 0.590\n",
      "2020-10-16 17:15:15.906910 Epoch: 100, Training loss: 1.051\n",
      "Accuracy: train 0.623\n",
      "Accuracy: validate 0.590\n"
     ]
    }
   ],
   "source": [
    "training_loop(100, opt, model, loss_fn, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 17:31:43.049340 Epoch: 1, Training loss: 1.050\n",
      "Accuracy: train 0.606\n",
      "Accuracy: validate 0.566\n",
      "2020-10-16 17:34:18.936782 Epoch: 10, Training loss: 1.032\n",
      "Accuracy: train 0.627\n",
      "Accuracy: validate 0.587\n",
      "2020-10-16 17:37:06.843294 Epoch: 20, Training loss: 1.012\n",
      "Accuracy: train 0.642\n",
      "Accuracy: validate 0.604\n",
      "2020-10-16 17:39:52.425294 Epoch: 30, Training loss: 0.995\n",
      "Accuracy: train 0.633\n",
      "Accuracy: validate 0.593\n",
      "2020-10-16 17:42:32.071045 Epoch: 40, Training loss: 0.977\n",
      "Accuracy: train 0.653\n",
      "Accuracy: validate 0.608\n",
      "2020-10-16 17:45:12.748039 Epoch: 50, Training loss: 0.961\n",
      "Accuracy: train 0.655\n",
      "Accuracy: validate 0.608\n",
      "2020-10-16 17:47:52.584042 Epoch: 60, Training loss: 0.945\n",
      "Accuracy: train 0.657\n",
      "Accuracy: validate 0.606\n",
      "2020-10-16 17:50:46.135725 Epoch: 70, Training loss: 0.929\n",
      "Accuracy: train 0.666\n",
      "Accuracy: validate 0.613\n",
      "2020-10-16 17:53:27.032729 Epoch: 80, Training loss: 0.916\n",
      "Accuracy: train 0.673\n",
      "Accuracy: validate 0.613\n",
      "2020-10-16 17:56:07.572725 Epoch: 90, Training loss: 0.903\n",
      "Accuracy: train 0.666\n",
      "Accuracy: validate 0.604\n",
      "2020-10-16 17:58:47.826694 Epoch: 100, Training loss: 0.889\n",
      "Accuracy: train 0.672\n",
      "Accuracy: validate 0.611\n"
     ]
    }
   ],
   "source": [
    "training_loop(100, opt, model, loss_fn, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 18:06:07.116517 Epoch: 1, Training loss: 0.888\n",
      "Accuracy: train 0.677\n",
      "Accuracy: validate 0.612\n",
      "2020-10-16 18:08:34.174513 Epoch: 10, Training loss: 0.876\n",
      "Accuracy: train 0.690\n",
      "Accuracy: validate 0.618\n",
      "2020-10-16 18:11:14.892565 Epoch: 20, Training loss: 0.865\n",
      "Accuracy: train 0.697\n",
      "Accuracy: validate 0.622\n",
      "2020-10-16 18:13:56.332562 Epoch: 30, Training loss: 0.853\n",
      "Accuracy: train 0.702\n",
      "Accuracy: validate 0.621\n",
      "2020-10-16 18:16:37.491341 Epoch: 40, Training loss: 0.842\n",
      "Accuracy: train 0.689\n",
      "Accuracy: validate 0.614\n",
      "2020-10-16 18:19:18.518339 Epoch: 50, Training loss: 0.831\n",
      "Accuracy: train 0.703\n",
      "Accuracy: validate 0.621\n",
      "2020-10-16 18:22:01.353352 Epoch: 60, Training loss: 0.820\n",
      "Accuracy: train 0.713\n",
      "Accuracy: validate 0.622\n",
      "2020-10-16 18:24:50.903193 Epoch: 70, Training loss: 0.810\n",
      "Accuracy: train 0.708\n",
      "Accuracy: validate 0.617\n",
      "2020-10-16 18:27:40.784209 Epoch: 80, Training loss: 0.801\n",
      "Accuracy: train 0.707\n",
      "Accuracy: validate 0.617\n",
      "2020-10-16 18:30:31.503314 Epoch: 90, Training loss: 0.792\n",
      "Accuracy: train 0.695\n",
      "Accuracy: validate 0.608\n",
      "2020-10-16 18:33:20.942340 Epoch: 100, Training loss: 0.783\n",
      "Accuracy: train 0.717\n",
      "Accuracy: validate 0.618\n"
     ]
    }
   ],
   "source": [
    "training_loop(100, opt, model, loss_fn, train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "data_path = 'C:\\\\Users\\\\Kyle\\\\Documents\\\\GitHub\\\\Learning-Repo\\\\PyTorch\\\\models\\\\'\n",
    "torch.save(model.state_dict(), data_path+'cifar_10_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
